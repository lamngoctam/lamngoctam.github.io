---

layout: post
title: Monte Carlo Path Tracer
date: May 20, 2019
framework: OpenGL
primary-language: C++
ide: QT Creator

---

<html>
<body>
    <div align=center>
        <figure>
            <img src="../../images/monte-carlo.png" width=75% height="auto" class="fade"></img>
            <figcaption>Various materials including metal, plastic, and glass on spheres.</figcaption>
        </figure>
    </div>
    <p>
    	For my final project in CIS 561 (Physically-based Rendering), I created a <b>Monte Carlo Path Tracer</b>.
    	Actually, it was a semester-long project, but the final project was where I got to freely 
    	explore into parts of building a renderer that I was interested in. If you're new to ray casting/rendering,
    	I would watch this video from Disney to make more sense of this post. <br />
        <br />
        The whole project boils down to the <b>Light Transport Equation (LTE)</b>, which I referenced religiously 
        throughout the process: <br />
        <br />
        <div align=center>
            Lo(p, ωo) = Le(p, ωo) + ∫_s f(p, ωo, ωi) Li(p, ωi) V(p', p) |dot(ωi, N)| dωi
        </div>
        <br />
        I also referenced <a href=https://www.pbrt.org>Physically-based Rendering: From Theory to Implementation</a>, which is a great resource
        with clear explanations of almost every concepts you may need to start a renderer from scratch. <br />
        <br />   
        I started with a naive implementation of the equation which just evaluate the Light Transport Equation 
        at every bounce of a ray from the camera and recusively calls it on each bounce (as you can imagine, 
        this would take very long to render each image). Below are some results and some metrics that I recorded: <br />
        <br />
        <div class="row">
            <div class="column">
                <figure>
                    <img src="../../images/mt-1.png" alt="Monte Carlo" width="73%" height="auto" class="fade">
                    <figcaption>Classic Cornell Box rendered with naive method, took approximately 10 minutes for 5 recursion depths.</figcaption>
                </figure>
            </div>
            <div class="column">
                <figure>
                    <img src="../../images/mt-2.png" alt="Monte Carlo" width="100%" height="auto" class="fade">
                    <figcaption>At 10 recursion depths, we see brighter result as more rays hit light source.</figcaption>
                </figure>
            </div>
        </div>
        <br />
        Later, I used various optimization methods to reduce the runtime of the renderer while preserving or even augmenting 
        the quality of the results. Although bouncing the rays may help us acheive a <b>global illumination</b> feel (which simply
        means objects near each other reflects light and bounces off to another object, thereby casting its color onto that other object),
        it might be worth trying a direct lighting approach, which eliminate the need for bouncing and only evaluates the LTE 
        once per ray. This method required no recursion and only counted rays which are visibible to light sources. This technique also 
        extends rays from light sources into the scene (instead of just from 
        the camera into the scene). <br />
        <br />
        Now, not having global illumination may be a big sacrifice, especially for those who are trying to achieve super realistic renders.
        In this case, I explored another method which takes the direct lighting technique and turns it up a notch, incorporating
        ray bounces while maintaining a reasonable runtime. This method is called <b>Multiple Importance Sampling</b> (MIS). MIS uses something 
        called the <b>Russian Roulette</b> trick, which terminates a fraction of rays from continue to bounce after a certain number of iterations, 
        and increases the influence of rays that bounces more to account for early terminated rays. MIS effectively shave off runtime
        while minimizing variation from the actual result. <br />
        <br />
        <figure align="center">
            <img src="../../images/veach.png" alt="Monte Carlo" width="auto" height="70%" class="fade">
            <figcaption>Variations of light sizes and roughness of materials.</figcaption>
        </figure>
    </br>
    <figure align="center">
        <img src="../../images/hanging_balls.png" alt="Monte Carlo" width="680" height="auto" class="fade">
        <figcaption>At 900 samples per pixel, this took around 1 hour to render on a MacBook Pro with Intel Core i5 compared to 3+ hours that the naive method would have taken.</figcaption>
    </figure>
    <br />
    For the final sections of the project, I decided to implement yet again another variation of the rendering methods from before.
    This time, I integrated support for volumetric substances, such as fog and smoke. This is very similar to MIS from before, 
    only treating the ray intersecting the scene a little differently. Rays from the camera now intersect both solid objects and 
    particles that represent the substance distributed throughout the space. I kept it simple and only considered homogeneous 
    particles, which makes use of Beer's Law to generate a uniform distribution throughout the scene. The great thing about these 
    particles is that they interact with light and transparant objects in interesting ways, as seen below with the green sphere
    with a bidirectional scattering distribution function involving transmittance. <br /> 
    <br />
    <figure align="center">
        <img src="../../images/transphere.png" alt="Monte Carlo" width="512" height="auto" class="fade">
        <figcaption>Transphere... Homogeneous fog-like particles interacting with a transmissive sphere.</figcaption>
    </figure> 
    For fun, I added some more light types like <b>spotlight</b> and <b>point light</b>. I also liked the look of <b>depth of field</b>, so I added a 
    lens camera class to replace the single point camera that was provided. One of the coolest features and a fun feature to play 
    around with was the <b>signed distance function</b> (SDF). I was able to create interesting shapes <a href="https://computergraphics.stackexchange.com/questions/161/what-is-ray-marching-is-sphere-tracing-the-same-thing"> sphere-marching </a> through mathematical 
    functions. My favorite has to be the mandelbulb: <br />
    <br />
    <figure align="center">
        <img src="../../images/mandy.png" alt="Monte Carlo" width="712" height="auto" class="fade">
        <figcaption>Mandelbulb with high noise intensity.</figcaption>
    </figure>
    <figure align="center">
        <img src="../../images/spot.png" alt="Monte Carlo" width="712" height="auto" class="fade">
        <figcaption>Just a plain simple spotlight!</figcaption>
    </figure>
    <figure align="center">
        <img src="../../images/chandy.PNG" alt="Monte Carlo" width="712" height="auto" class="fade">
        <figcaption>Featuring a lens camera for some depth of field effect.</figcaption>
    </figure>         
    <br />
    There were lots of other smaller features such as Bidirectional Scattering Distribution Functions that we implemented like microfacet and Oren-Nayar, just
    to name a few. Coding a renderer from scratch was a huge learning opportunity for me, both to get to the niddy gritty C++ styles and practices
    that I overlooked, to how rays actually interact with objects, to shadows and many others. If you're interested, I highly recommend starting with 
    Physically-based Rendering book. Other resources include this <a href=http://www.realtimerendering.com/raytracing/Ray%20Tracing%20in%20a%20Weekend.pdf>
    Ray Tracing in One Weekend</a> series, where the author goes through building a super condensed version of prbt. I'm moving on to real-time ray-tracing,
    so wish me luck! I'll write about this in another project post so stay tuned...
    <br />
</p>
</body>
</html>